{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0601803c-7b54-4717-8f9a-6b30a3220143",
   "metadata": {},
   "source": [
    "## Data Cleaning for Wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2051b99a-bec3-456d-9cd1-79ae4d2da96c",
   "metadata": {},
   "source": [
    "### This script contains the following:\n",
    "\n",
    "#### 1. Importing libraries and data\n",
    "#### 2. Data cleaning for wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6546a8a5-11aa-4e09-b724-2f1034e6888f",
   "metadata": {},
   "source": [
    "### 1. Importing libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc6d617f-75ab-4d91-8d25-5d9b0e6fe231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from fuzzywuzzy import process\n",
    "from rapidfuzz import process, fuzz\n",
    "from collections import Counter\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "070648ff-4301-4a74-8e31-6c684932eaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path\n",
    "path = r'C:\\Users\\16307\\Desktop\\Tasks - DA Immersion\\Gun Violence Analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "683a8350-a820-4491-b409-e7b682bb0936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "df = pd.read_csv(os.path.join(path, '02 Data', 'gun_violence_cleaned4.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "059acfaf-95fb-4815-9f4e-39eeb530fa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset DataFrame with only the 'location_description' column\n",
    "location_df = df[['location_description']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87139ceb-a118-40f5-b9ab-8908967e5ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'location_description' column to string and handle NaN values\n",
    "location_df['location_description'] = location_df['location_description'].astype(str).fillna('')\n",
    "\n",
    "# Preprocessing: Bucket names based on their first 3 characters (this can be adjusted)\n",
    "def bucket_by_initials(df, column, bucket_size=3):\n",
    "    df['bucket'] = df[column].str[:bucket_size].str.lower()\n",
    "    return df\n",
    "\n",
    "# Function to find similar location descriptions in chunks\n",
    "def find_similar_in_chunk(names_chunk, all_names, threshold=80):\n",
    "    similar_names_chunk = []\n",
    "    for name in names_chunk:\n",
    "        if name.strip():\n",
    "            matches = process.extract(name, all_names, scorer=fuzz.ratio, limit=None)\n",
    "            similar_names = [match[0] for match in matches if match[1] >= threshold]\n",
    "            similar_names_chunk.append(similar_names)\n",
    "    return similar_names_chunk\n",
    "\n",
    "# Split data into chunks and process in parallel\n",
    "def parallel_find_similar_names(location_df, column, num_workers=4, threshold=80):\n",
    "    all_names = location_df[column].unique()\n",
    "    name_chunks = np.array_split(all_names, num_workers)\n",
    "    \n",
    "    with Pool(num_workers) as pool:\n",
    "        results = pool.starmap(find_similar_in_chunk, [(chunk, all_names, threshold) for chunk in name_chunks])\n",
    "    \n",
    "    # Flatten results from all workers\n",
    "    similar_names = [item for sublist in results for item in sublist]\n",
    "    return similar_names\n",
    "\n",
    "# Preprocess by bucketing based on first few characters\n",
    "location_df = bucket_by_initials(location_df, 'location_description', bucket_size=3)\n",
    "\n",
    "# Get all unique buckets\n",
    "buckets = location_df['bucket'].unique()\n",
    "\n",
    "# For each bucket, find similar names within that bucket\n",
    "name_mapping = {}\n",
    "for bucket in buckets:\n",
    "    bucket_df = location_df[location_df['bucket'] == bucket]\n",
    "    similar_names = parallel_find_similar_names(bucket_df, 'location_description', num_workers=4, threshold=80)\n",
    "    \n",
    "    # Create a mapping for standardized names based on the most common name in each group\n",
    "    for group in similar_names:\n",
    "        most_common_name = Counter(group).most_common(1)[0][0]\n",
    "        for name in group:\n",
    "            name_mapping[name] = most_common_name\n",
    "\n",
    "# Replace the original names with standardized names in the DataFrame\n",
    "location_df['standardized_location_description'] = location_df['location_description'].map(name_mapping).fillna(location_df['location_description'])\n",
    "\n",
    "# Drop the bucket column and save the DataFrame with standardized names to a new CSV file\n",
    "location_df.drop('bucket', axis=1, inplace=True)\n",
    "location_df.to_csv('standardized_data.csv', index=False)\n",
    "\n",
    "# Display the results\n",
    "print(location_df[['location_description', 'standardized_location_description']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df91aed-2cd8-4edb-a5d4-34ef69d8354a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
